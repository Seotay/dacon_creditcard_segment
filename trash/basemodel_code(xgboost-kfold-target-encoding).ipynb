{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import gc\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from utils.reduce_memory import trainform_columns_type\n",
    "from utils.target_encoding import target_encode, TargetEncoder\n",
    "import xgboost as xgb\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단일 값 가지는 컬럼 & NULL 값 가지는 컬럼 모두 제거."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet('./data/train/train_filtered.parquet')\n",
    "test_df = pd.read_parquet('./data/test/test_filtered.parquet')\n",
    "\n",
    "# reduce memory by chaing data types of columns\n",
    "train_df = trainform_columns_type(train_df)\n",
    "test_df = trainform_columns_type(test_df)\n",
    "\n",
    "print('shape of train dataset(drop colums)', train_df.shape)\n",
    "print('shape of test dataset(drop colums)', test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>기준년월</th>\n",
       "      <th>ID</th>\n",
       "      <th>남녀구분코드</th>\n",
       "      <th>연령</th>\n",
       "      <th>Segment</th>\n",
       "      <th>회원여부_이용가능</th>\n",
       "      <th>회원여부_이용가능_CA</th>\n",
       "      <th>회원여부_이용가능_카드론</th>\n",
       "      <th>소지여부_신용</th>\n",
       "      <th>소지카드수_유효_신용</th>\n",
       "      <th>...</th>\n",
       "      <th>변동률_RV일시불평잔</th>\n",
       "      <th>변동률_할부평잔</th>\n",
       "      <th>변동률_CA평잔</th>\n",
       "      <th>변동률_RVCA평잔</th>\n",
       "      <th>변동률_카드론평잔</th>\n",
       "      <th>변동률_잔액_B1M</th>\n",
       "      <th>변동률_잔액_일시불_B1M</th>\n",
       "      <th>변동률_잔액_CA_B1M</th>\n",
       "      <th>혜택수혜율_R3M</th>\n",
       "      <th>혜택수혜율_B0M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201807</td>\n",
       "      <td>TRAIN_000000</td>\n",
       "      <td>2</td>\n",
       "      <td>40대</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.042805</td>\n",
       "      <td>0.999700</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.261886</td>\n",
       "      <td>0.270752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.044401</td>\n",
       "      <td>1.280542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201807</td>\n",
       "      <td>TRAIN_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>30대</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.092698</td>\n",
       "      <td>0.905663</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.563388</td>\n",
       "      <td>-0.670348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201807</td>\n",
       "      <td>TRAIN_000002</td>\n",
       "      <td>1</td>\n",
       "      <td>30대</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.006124</td>\n",
       "      <td>1.993590</td>\n",
       "      <td>0.852567</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.046516</td>\n",
       "      <td>0.058114</td>\n",
       "      <td>-0.014191</td>\n",
       "      <td>0.524159</td>\n",
       "      <td>1.208420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201807</td>\n",
       "      <td>TRAIN_000003</td>\n",
       "      <td>2</td>\n",
       "      <td>40대</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.050646</td>\n",
       "      <td>0.999877</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.023821</td>\n",
       "      <td>0.258943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880925</td>\n",
       "      <td>1.657124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201807</td>\n",
       "      <td>TRAIN_000004</td>\n",
       "      <td>2</td>\n",
       "      <td>40대</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399995</th>\n",
       "      <td>201812</td>\n",
       "      <td>TRAIN_399995</td>\n",
       "      <td>2</td>\n",
       "      <td>70대이상</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399996</th>\n",
       "      <td>201812</td>\n",
       "      <td>TRAIN_399996</td>\n",
       "      <td>2</td>\n",
       "      <td>50대</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.921733</td>\n",
       "      <td>-0.203251</td>\n",
       "      <td>-0.159143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.377071</td>\n",
       "      <td>2.533815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399997</th>\n",
       "      <td>201812</td>\n",
       "      <td>TRAIN_399997</td>\n",
       "      <td>1</td>\n",
       "      <td>30대</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.345027</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.027319</td>\n",
       "      <td>0.126581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399998</th>\n",
       "      <td>201812</td>\n",
       "      <td>TRAIN_399998</td>\n",
       "      <td>1</td>\n",
       "      <td>40대</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399999</th>\n",
       "      <td>201812</td>\n",
       "      <td>TRAIN_399999</td>\n",
       "      <td>2</td>\n",
       "      <td>40대</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.593160</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.039845</td>\n",
       "      <td>-0.002659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400000 rows × 743 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           기준년월            ID  남녀구분코드     연령 Segment  회원여부_이용가능  회원여부_이용가능_CA  \\\n",
       "0        201807  TRAIN_000000       2    40대       D          1             1   \n",
       "1        201807  TRAIN_000001       1    30대       E          1             1   \n",
       "2        201807  TRAIN_000002       1    30대       C          1             1   \n",
       "3        201807  TRAIN_000003       2    40대       D          1             1   \n",
       "4        201807  TRAIN_000004       2    40대       E          1             1   \n",
       "...         ...           ...     ...    ...     ...        ...           ...   \n",
       "2399995  201812  TRAIN_399995       2  70대이상       E          1             1   \n",
       "2399996  201812  TRAIN_399996       2    50대       D          1             1   \n",
       "2399997  201812  TRAIN_399997       1    30대       C          1             1   \n",
       "2399998  201812  TRAIN_399998       1    40대       E          1             1   \n",
       "2399999  201812  TRAIN_399999       2    40대       E          1             1   \n",
       "\n",
       "         회원여부_이용가능_카드론  소지여부_신용  소지카드수_유효_신용  ...  변동률_RV일시불평잔  변동률_할부평잔  \\\n",
       "0                    0        1            1  ...     0.999998  1.042805   \n",
       "1                    1        1            1  ...     1.092698  0.905663   \n",
       "2                    0        1            1  ...     1.006124  1.993590   \n",
       "3                    0        1            2  ...     0.999998  1.050646   \n",
       "4                    1        1            1  ...     0.999998  0.999998   \n",
       "...                ...      ...          ...  ...          ...       ...   \n",
       "2399995              1        1            1  ...     0.999998  0.999998   \n",
       "2399996              1        1            1  ...     0.999998  0.999998   \n",
       "2399997              0        1            1  ...     0.999998  0.345027   \n",
       "2399998              1        1            1  ...     0.999998  0.999998   \n",
       "2399999              0        1            1  ...     0.999998  0.593160   \n",
       "\n",
       "         변동률_CA평잔  변동률_RVCA평잔  변동률_카드론평잔  변동률_잔액_B1M  변동률_잔액_일시불_B1M  \\\n",
       "0        0.999700    0.999998   0.999998    0.261886        0.270752   \n",
       "1        0.999998    0.999998   0.999998   -0.563388       -0.670348   \n",
       "2        0.852567    0.999998   0.999998   -0.046516        0.058114   \n",
       "3        0.999877    0.999998   0.999998    0.023821        0.258943   \n",
       "4        0.999998    0.999998   0.999998    0.000000        0.000000   \n",
       "...           ...         ...        ...         ...             ...   \n",
       "2399995  0.999998    0.999998   0.999998    0.000000        0.000000   \n",
       "2399996  0.999998    0.999998   0.921733   -0.203251       -0.159143   \n",
       "2399997  0.999998    0.999998   0.999998    0.027319        0.126581   \n",
       "2399998  0.999998    0.999998   0.999998    0.000000        0.000000   \n",
       "2399999  0.999998    0.999998   0.999998   -0.039845       -0.002659   \n",
       "\n",
       "         변동률_잔액_CA_B1M  혜택수혜율_R3M  혜택수혜율_B0M  \n",
       "0             0.000000   1.044401   1.280542  \n",
       "1             0.000000   0.000000   0.000000  \n",
       "2            -0.014191   0.524159   1.208420  \n",
       "3             0.000000   0.880925   1.657124  \n",
       "4             0.000000        NaN        NaN  \n",
       "...                ...        ...        ...  \n",
       "2399995       0.000000        NaN        NaN  \n",
       "2399996       0.000000   1.377071   2.533815  \n",
       "2399997       0.000000   0.000000   0.000000  \n",
       "2399998       0.000000        NaN        NaN  \n",
       "2399999       0.000000   0.000000   0.000000  \n",
       "\n",
       "[2400000 rows x 743 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train dataset(drop colums to have null values) (2400000, 712)\n",
      "shape of test dataset(drop colums to have null values) (600000, 711)\n"
     ]
    }
   ],
   "source": [
    "# remove columns to have null values\n",
    "null_cols = train_df.columns[train_df.isnull().any()]\n",
    "train_df = train_df.drop(columns=null_cols)          \n",
    "test_df = test_df.drop(columns=null_cols, errors='ignore')\n",
    "print('shape of train dataset(drop colums to have null values)', train_df.shape)\n",
    "print('shape of test dataset(drop colums to have null values)', test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "기준년월                int32\n",
       "ID                 object\n",
       "남녀구분코드              int32\n",
       "연령                 object\n",
       "Segment            object\n",
       "                   ...   \n",
       "변동률_RVCA평잔        float32\n",
       "변동률_카드론평잔         float32\n",
       "변동률_잔액_B1M        float32\n",
       "변동률_잔액_일시불_B1M    float32\n",
       "변동률_잔액_CA_B1M     float32\n",
       "Length: 712, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split X, y in train datasets 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          3.707884\n",
      "1          3.717624\n",
      "2          3.717624\n",
      "3          3.707884\n",
      "4          3.707884\n",
      "             ...   \n",
      "2399995    3.840038\n",
      "2399996    3.758679\n",
      "2399997    3.717624\n",
      "2399998    3.707884\n",
      "2399999    3.707884\n",
      "Name: 연령, Length: 2400000, dtype: float64\n",
      "0          3.730498\n",
      "1          3.703061\n",
      "2          3.730498\n",
      "3          3.805835\n",
      "4          3.785892\n",
      "             ...   \n",
      "2399995    3.747230\n",
      "2399996    3.774259\n",
      "2399997    3.730498\n",
      "2399998    3.805835\n",
      "2399999    3.804816\n",
      "Name: 거주시도명, Length: 2400000, dtype: float64\n",
      "0          3.746502\n",
      "1          3.746502\n",
      "2          3.746502\n",
      "3          3.746502\n",
      "4          3.746502\n",
      "             ...   \n",
      "2399995    3.746502\n",
      "2399996    3.746502\n",
      "2399997    3.746502\n",
      "2399998    3.746502\n",
      "2399999    3.746502\n",
      "Name: 연회비발생카드수_B0M, Length: 2400000, dtype: float64\n",
      "0          3.749090\n",
      "1          3.702741\n",
      "2          3.709390\n",
      "3          3.749090\n",
      "4          3.702741\n",
      "             ...   \n",
      "2399995    3.836794\n",
      "2399996    3.749090\n",
      "2399997    3.709390\n",
      "2399998    3.702741\n",
      "2399999    3.702741\n",
      "Name: Life_Stage, Length: 2400000, dtype: float64\n",
      "0          3.746453\n",
      "1          3.746453\n",
      "2          3.746453\n",
      "3          3.746453\n",
      "4          3.746453\n",
      "             ...   \n",
      "2399995    3.746453\n",
      "2399996    3.746453\n",
      "2399997    3.746453\n",
      "2399998    3.746453\n",
      "2399999    3.746453\n",
      "Name: 자발한도감액횟수_R12M, Length: 2400000, dtype: float64\n",
      "0          3.758557\n",
      "1          3.758557\n",
      "2          3.758557\n",
      "3          3.758557\n",
      "4          3.758557\n",
      "             ...   \n",
      "2399995    3.758557\n",
      "2399996    3.655419\n",
      "2399997    3.758557\n",
      "2399998    3.758557\n",
      "2399999    3.655419\n",
      "Name: 한도증액횟수_R12M, Length: 2400000, dtype: float64\n",
      "0          3.736450\n",
      "1          3.736450\n",
      "2          3.736450\n",
      "3          3.736450\n",
      "4          3.736450\n",
      "             ...   \n",
      "2399995    3.736450\n",
      "2399996    3.736450\n",
      "2399997    3.736450\n",
      "2399998    3.736450\n",
      "2399999    3.786591\n",
      "Name: 카드론동의여부, Length: 2400000, dtype: float64\n",
      "0          3.746364\n",
      "1          3.746364\n",
      "2          3.746364\n",
      "3          3.746364\n",
      "4          3.746364\n",
      "             ...   \n",
      "2399995    3.746364\n",
      "2399996    3.746364\n",
      "2399997    3.746364\n",
      "2399998    3.746364\n",
      "2399999    3.746364\n",
      "Name: 한도심사요청건수, Length: 2400000, dtype: float64\n",
      "0          2.979342\n",
      "1          3.918006\n",
      "2          2.979342\n",
      "3          2.979342\n",
      "4          3.947932\n",
      "             ...   \n",
      "2399995    3.947932\n",
      "2399996    2.979342\n",
      "2399997    3.707075\n",
      "2399998    3.947932\n",
      "2399999    3.899079\n",
      "Name: 이용금액대, Length: 2400000, dtype: float64\n",
      "0          3.696702\n",
      "1          3.797119\n",
      "2          3.696702\n",
      "3          3.797119\n",
      "4          3.797119\n",
      "             ...   \n",
      "2399995    3.797119\n",
      "2399996    3.696702\n",
      "2399997    3.761584\n",
      "2399998    3.797119\n",
      "2399999    3.797119\n",
      "Name: 대표청구지고객주소구분코드, Length: 2400000, dtype: float64\n",
      "0          3.751611\n",
      "1          3.789488\n",
      "2          3.681486\n",
      "3          3.789488\n",
      "4          3.789488\n",
      "             ...   \n",
      "2399995    3.789488\n",
      "2399996    3.681486\n",
      "2399997    3.789488\n",
      "2399998    3.789488\n",
      "2399999    3.789488\n",
      "Name: 대표청구서수령지구분코드, Length: 2400000, dtype: float64\n",
      "0          3.751612\n",
      "1          3.789488\n",
      "2          3.681486\n",
      "3          3.789488\n",
      "4          3.789488\n",
      "             ...   \n",
      "2399995    3.789488\n",
      "2399996    3.681486\n",
      "2399997    3.789488\n",
      "2399998    3.789488\n",
      "2399999    3.789488\n",
      "Name: 청구서수령방법, Length: 2400000, dtype: float64\n",
      "0          3.792223\n",
      "1          3.792223\n",
      "2          3.792223\n",
      "3          3.792223\n",
      "4          3.792223\n",
      "             ...   \n",
      "2399995    3.792223\n",
      "2399996    3.792223\n",
      "2399997    3.792223\n",
      "2399998    3.792223\n",
      "2399999    3.792223\n",
      "Name: 할인건수_R3M, Length: 2400000, dtype: float64\n",
      "0          3.749807\n",
      "1          3.749807\n",
      "2          3.749807\n",
      "3          3.749807\n",
      "4          3.749807\n",
      "             ...   \n",
      "2399995    3.749807\n",
      "2399996    3.749807\n",
      "2399997    3.749807\n",
      "2399998    3.749807\n",
      "2399999    3.749807\n",
      "Name: 할인건수_B0M, Length: 2400000, dtype: float64\n",
      "0          3.403422\n",
      "1          3.756822\n",
      "2          3.756822\n",
      "3          3.403422\n",
      "4          3.756822\n",
      "             ...   \n",
      "2399995    3.756822\n",
      "2399996    3.756822\n",
      "2399997    3.756822\n",
      "2399998    3.756822\n",
      "2399999    3.756822\n",
      "Name: 인입횟수_ARS_R6M, Length: 2400000, dtype: float64\n",
      "0          3.445757\n",
      "1          3.757606\n",
      "2          3.757606\n",
      "3          3.445757\n",
      "4          3.757606\n",
      "             ...   \n",
      "2399995    3.757606\n",
      "2399996    3.757606\n",
      "2399997    3.757606\n",
      "2399998    3.757606\n",
      "2399999    3.757606\n",
      "Name: 이용메뉴건수_ARS_R6M, Length: 2400000, dtype: float64\n",
      "0          3.769402\n",
      "1          3.769402\n",
      "2          3.468281\n",
      "3          3.769402\n",
      "4          3.769402\n",
      "             ...   \n",
      "2399995    3.769402\n",
      "2399996    3.769402\n",
      "2399997    3.769402\n",
      "2399998    3.769402\n",
      "2399999    3.769402\n",
      "Name: 방문횟수_PC_R6M, Length: 2400000, dtype: float64\n",
      "0          3.767363\n",
      "1          3.767363\n",
      "2          3.461234\n",
      "3          3.767363\n",
      "4          3.767363\n",
      "             ...   \n",
      "2399995    3.767363\n",
      "2399996    3.767363\n",
      "2399997    3.767363\n",
      "2399998    3.767363\n",
      "2399999    3.767363\n",
      "Name: 방문일수_PC_R6M, Length: 2400000, dtype: float64\n",
      "0          3.775586\n",
      "1          3.775586\n",
      "2          3.554478\n",
      "3          3.775586\n",
      "4          3.775586\n",
      "             ...   \n",
      "2399995    3.775586\n",
      "2399996    3.775586\n",
      "2399997    3.775586\n",
      "2399998    3.775586\n",
      "2399999    3.775586\n",
      "Name: 방문횟수_앱_R6M, Length: 2400000, dtype: float64\n",
      "0          3.733131\n",
      "1          3.750364\n",
      "2          3.733131\n",
      "3          3.733131\n",
      "4          3.733131\n",
      "             ...   \n",
      "2399995    3.733131\n",
      "2399996    3.732396\n",
      "2399997    3.733131\n",
      "2399998    3.733131\n",
      "2399999    3.733131\n",
      "Name: 캠페인접촉건수_R12M, Length: 2400000, dtype: float64\n",
      "0          3.733381\n",
      "1          3.772181\n",
      "2          3.733381\n",
      "3          3.733381\n",
      "4          3.733381\n",
      "             ...   \n",
      "2399995    3.733381\n",
      "2399996    3.745544\n",
      "2399997    3.733381\n",
      "2399998    3.733381\n",
      "2399999    3.733381\n",
      "Name: 캠페인접촉일수_R12M, Length: 2400000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# X: ID, Segement 제거\n",
    "# y: Segment 추출\n",
    "feature_cols = [col for col in train_df.columns if col not in [\"ID\", \"Segment\"]]\n",
    "\n",
    "X = train_df[feature_cols].copy() \n",
    "y = train_df[\"Segment\"].copy() \n",
    "\n",
    "# Target Label Encoding\n",
    "le_target = LabelEncoder()\n",
    "\n",
    "y_encoded = le_target.fit_transform(y)\n",
    "\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "X_test = test_df.copy()\n",
    "\n",
    "encoders = {}  # 각 컬럼별 encoder 저장\n",
    "\n",
    "for col in categorical_features:\n",
    "    \n",
    "    le_train = TargetEncoder()\n",
    "    X[col] = le_train.fit_transform(X[[col]], y_encoded)\n",
    "    print(X[col])\n",
    "    encoders[col] = le_train\n",
    "    #unseen_labels_val = set(X_test[col]) - set(le_train.classes_)\n",
    "    #if unseen_labels_val:\n",
    "    #    le_train.classes_ = np.append(le_train.classes_, list(unseen_labels_val))\n",
    "    X_test[col] = le_train.transform(X_test[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "classes = np.unique(y_encoded)\n",
    "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_encoded)\n",
    "class_weight_dict = dict(zip(classes, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 493.82716049382714,\n",
       " 1: 3333.3333333333335,\n",
       " 2: 3.7620503174229953,\n",
       " 3: 1.3744051402752246,\n",
       " 4: 0.2497330977517778}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.37440514, 0.2497331 , 3.76205032, ..., 3.76205032, 0.2497331 ,\n",
       "       0.2497331 ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weights = np.array([class_weight_dict[y] for y in y_encoded])\n",
    "sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Fold 1-th XGBoost model training...\n",
      "Fold 1 Accuracy: 0.8889\n",
      "Fold 1 Recall: 0.8806\n",
      "Fold 1 Precision: 0.7962\n",
      "Fold 1 F1-score: 0.8306\n",
      "Fold 1 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.95      0.86       201\n",
      "           1       0.95      0.89      0.92        45\n",
      "           2       0.63      0.86      0.73     25532\n",
      "           3       0.62      0.81      0.70     69969\n",
      "           4       0.98      0.91      0.94    384253\n",
      "\n",
      "    accuracy                           0.89    480000\n",
      "   macro avg       0.80      0.88      0.83    480000\n",
      "weighted avg       0.91      0.89      0.90    480000\n",
      "\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Fold 2-th XGBoost model training...\n",
      "Fold 2 Accuracy: 0.8887\n",
      "Fold 2 Recall: 0.8908\n",
      "Fold 2 Precision: 0.7876\n",
      "Fold 2 F1-score: 0.8310\n",
      "Fold 2 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.93      0.83       169\n",
      "           1       0.95      0.95      0.95        20\n",
      "           2       0.64      0.86      0.73     25641\n",
      "           3       0.62      0.81      0.70     70156\n",
      "           4       0.98      0.91      0.94    384014\n",
      "\n",
      "    accuracy                           0.89    480000\n",
      "   macro avg       0.79      0.89      0.83    480000\n",
      "weighted avg       0.91      0.89      0.90    480000\n",
      "\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Fold 3-th XGBoost model training...\n",
      "Fold 3 Accuracy: 0.8906\n",
      "Fold 3 Recall: 0.8638\n",
      "Fold 3 Precision: 0.7704\n",
      "Fold 3 F1-score: 0.8088\n",
      "Fold 3 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.93      0.83       179\n",
      "           1       0.87      0.81      0.84        32\n",
      "           2       0.64      0.86      0.73     25375\n",
      "           3       0.62      0.81      0.70     69752\n",
      "           4       0.99      0.91      0.94    384662\n",
      "\n",
      "    accuracy                           0.89    480000\n",
      "   macro avg       0.77      0.86      0.81    480000\n",
      "weighted avg       0.91      0.89      0.90    480000\n",
      "\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Fold 4-th XGBoost model training...\n",
      "Fold 4 Accuracy: 0.8891\n",
      "Fold 4 Recall: 0.8676\n",
      "Fold 4 Precision: 0.8119\n",
      "Fold 4 F1-score: 0.8324\n",
      "Fold 4 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86       208\n",
      "           1       1.00      0.88      0.93        16\n",
      "           2       0.63      0.86      0.73     25327\n",
      "           3       0.62      0.81      0.70     69890\n",
      "           4       0.98      0.91      0.94    384559\n",
      "\n",
      "    accuracy                           0.89    480000\n",
      "   macro avg       0.81      0.87      0.83    480000\n",
      "weighted avg       0.91      0.89      0.90    480000\n",
      "\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Fold 5-th XGBoost model training...\n",
      "Fold 5 Accuracy: 0.8886\n",
      "Fold 5 Recall: 0.8250\n",
      "Fold 5 Precision: 0.7882\n",
      "Fold 5 F1-score: 0.7930\n",
      "Fold 5 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.91      0.83       215\n",
      "           1       0.95      0.65      0.77        31\n",
      "           2       0.64      0.85      0.73     25715\n",
      "           3       0.61      0.81      0.70     69475\n",
      "           4       0.99      0.91      0.94    384564\n",
      "\n",
      "    accuracy                           0.89    480000\n",
      "   macro avg       0.79      0.83      0.79    480000\n",
      "weighted avg       0.91      0.89      0.90    480000\n",
      "\n",
      "----------------------------------------\n",
      "K-Fold mean Accuracy: 0.8892\n",
      "K-Fold mean Recall: 0.8656\n",
      "K-Fold mean Precision: 0.7909\n",
      "K-Fold mean F1-score: 0.8192\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "models = [] \n",
    "accuracy_scores = []\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "fi_scores = []\n",
    "classification_reports = []\n",
    "\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
    "    sample_weights_fold = sample_weights[train_idx]\n",
    "    print('-'*40)\n",
    "    print(f'Fold {fold + 1}-th XGBoost model training...')\n",
    "    \n",
    "    # XGBoost\n",
    "    model = xgb.XGBClassifier(\n",
    "        tree_method='gpu_hist',  # GPU mode\n",
    "        gpu_id=0,\n",
    "        random_state=42,\n",
    "        sample_weight=sample_weights_fold,\n",
    "        use_label_encoder=False)\n",
    "    \n",
    "    # training and validation mornitoring\n",
    "    \n",
    "    model.fit(X_train, y_train, sample_weight=sample_weights[train_idx])\n",
    "    models.append(model)\n",
    "\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    recall = recall_score(y_val, y_val_pred, average='macro')\n",
    "    precision = precision_score(y_val, y_val_pred, average='macro')\n",
    "    f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "    report = classification_report(y_val, y_val_pred)\n",
    "    conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Fold {fold + 1} Recall: {recall:.4f}\")\n",
    "    print(f\"Fold {fold + 1} Precision: {precision:.4f}\")\n",
    "    print(f\"Fold {fold + 1} F1-score: {f1:.4f}\")\n",
    "    print(f\"Fold {fold + 1} Classification Report\\n:{report}\")\n",
    "    print(f\"Fold {fold + 1} Confusion Matrix:\\n{conf_matrix}\")\n",
    "    print('-'*40)\n",
    "    \n",
    "    accuracy_scores.append(accuracy)\n",
    "    recall_scores.append(recall)\n",
    "    precision_scores.append(precision)\n",
    "    fi_scores.append(f1)\n",
    "    \n",
    "    \n",
    "print(f\"K-Fold mean Accuracy: {np.mean(accuracy_scores):.4f}\")\n",
    "print(f\"K-Fold mean Recall: {np.mean(recall_scores):.4f}\")\n",
    "print(f\"K-Fold mean Precision: {np.mean(precision_scores):.4f}\")\n",
    "print(f\"K-Fold mean F1-score: {np.mean(fi_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.drop(columns=['ID'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft Voting Inference Done.\n"
     ]
    }
   ],
   "source": [
    "n_classes = models[0].n_classes_ \n",
    "test_probabilities = np.zeros((len(X_test), n_classes)) # (600000, 5)\n",
    "\n",
    "for model in models:\n",
    "    test_probabilities += model.predict_proba(X_test) # (600000, 5)\n",
    "\n",
    "test_probabilities /= len(models)\n",
    "test_predictions = np.argmax(test_probabilities, axis=1)\n",
    "\n",
    "print('Soft Voting Inference Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_labels = le_target.inverse_transform(test_predictions)\n",
    "\n",
    "# row 단위 예측 결과를 test_data에 추가\n",
    "test_data = test_df.copy()  # 원본 유지\n",
    "test_data[\"pred_label\"] = y_test_pred_labels\n",
    "\n",
    "submission = test_data.groupby(\"ID\")[\"pred_label\"] \\\n",
    "    .agg(lambda x: x.value_counts().idxmax()) \\\n",
    "    .reset_index()\n",
    "\n",
    "submission.columns = [\"ID\", \"Segment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00000</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>TEST_99995</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>TEST_99996</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>TEST_99997</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>TEST_99998</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>TEST_99999</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID Segment\n",
       "0      TEST_00000       D\n",
       "1      TEST_00001       D\n",
       "2      TEST_00002       D\n",
       "3      TEST_00003       E\n",
       "4      TEST_00004       E\n",
       "...           ...     ...\n",
       "99995  TEST_99995       E\n",
       "99996  TEST_99996       E\n",
       "99997  TEST_99997       E\n",
       "99998  TEST_99998       C\n",
       "99999  TEST_99999       E\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./results/0327_xgboost_K5fold(class_weight-target_encoding-nosmoothing).csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taehyeok",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
