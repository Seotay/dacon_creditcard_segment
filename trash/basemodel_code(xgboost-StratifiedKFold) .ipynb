{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import gc\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from utils.reduce_memory import trainform_columns_type\n",
    "import xgboost as xgb\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단일 값 가지는 컬럼 & NULL 값 가지는 컬럼 모두 제거."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train dataset(drop colums) (2400000, 743)\n",
      "shape of test dataset(drop colums) (600000, 742)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_parquet('./data/train/train_filtered.parquet')\n",
    "test_df = pd.read_parquet('./data/test/test_filtered.parquet')\n",
    "\n",
    "# reduce memory by chaing data types of columns\n",
    "train_df = trainform_columns_type(train_df)\n",
    "test_df = trainform_columns_type(test_df)\n",
    "\n",
    "print('shape of train dataset(drop colums)', train_df.shape)\n",
    "print('shape of test dataset(drop colums)', test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train dataset(drop colums to have null values) (2400000, 712)\n",
      "shape of test dataset(drop colums to have null values) (600000, 711)\n"
     ]
    }
   ],
   "source": [
    "# remove columns to have null values\n",
    "null_cols = train_df.columns[train_df.isnull().any()]\n",
    "train_df = train_df.drop(columns=null_cols)          \n",
    "test_df = test_df.drop(columns=null_cols, errors='ignore')\n",
    "print('shape of train dataset(drop colums to have null values)', train_df.shape)\n",
    "print('shape of test dataset(drop colums to have null values)', test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "기준년월                int32\n",
       "ID                 object\n",
       "남녀구분코드              int32\n",
       "연령                 object\n",
       "Segment            object\n",
       "                   ...   \n",
       "변동률_RVCA평잔        float32\n",
       "변동률_카드론평잔         float32\n",
       "변동률_잔액_B1M        float32\n",
       "변동률_잔액_일시불_B1M    float32\n",
       "변동률_잔액_CA_B1M     float32\n",
       "Length: 712, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split X, y in train datasets 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X: ID, Segement 제거\n",
    "# y: Segment 추출\n",
    "feature_cols = [col for col in train_df.columns if col not in [\"ID\", \"Segment\"]]\n",
    "\n",
    "X = train_df[feature_cols].copy()\n",
    "y = train_df[\"Segment\"].copy()\n",
    "\n",
    "# Target Label Encoding\n",
    "le_target = LabelEncoder()\n",
    "y_encoded = le_target.fit_transform(y)\n",
    "\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "X_test = test_df.copy()\n",
    "\n",
    "encoders = {}  # 각 컬럼별 encoder 저장\n",
    "\n",
    "for col in categorical_features:\n",
    "    le_train = LabelEncoder()\n",
    "    X[col] = le_train.fit_transform(X[col])\n",
    "    encoders[col] = le_train\n",
    "    unseen_labels_val = set(X_test[col]) - set(le_train.classes_)\n",
    "    if unseen_labels_val:\n",
    "        le_train.classes_ = np.append(le_train.classes_, list(unseen_labels_val))\n",
    "    X_test[col] = le_train.transform(X_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "classes = np.unique(y_encoded)\n",
    "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_encoded)\n",
    "class_weight_dict = dict(zip(classes, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.37440514, 0.2497331 , 3.76205032, ..., 3.76205032, 0.2497331 ,\n",
       "       0.2497331 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weights = np.array([class_weight_dict[y] for y in y_encoded])\n",
    "sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "stratified Fold 1-th XGBoost model training...\n",
      "Fold 1 Accuracy: 0.8861\n",
      "Fold 1 Recall: 0.8876\n",
      "Fold 1 Precision: 0.7860\n",
      "Fold 1 F1-score: 0.8281\n",
      "Fold 1 Classification Report\n",
      ":              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       195\n",
      "           1       0.89      0.89      0.89        28\n",
      "           2       0.63      0.89      0.73     25518\n",
      "           3       0.61      0.80      0.69     69849\n",
      "           4       0.99      0.90      0.94    384410\n",
      "\n",
      "    accuracy                           0.89    480000\n",
      "   macro avg       0.79      0.89      0.83    480000\n",
      "weighted avg       0.91      0.89      0.89    480000\n",
      "\n",
      "Fold 1 Confusion Matrix:\n",
      "[[   186      2      7      0      0]\n",
      " [     0     25      3      0      0]\n",
      " [    33      1  22707   2545    232]\n",
      " [     3      0   9607  55858   4381]\n",
      " [     5      0   3952  33901 346552]]\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "stratified Fold 2-th XGBoost model training...\n",
      "Fold 2 Accuracy: 0.8935\n",
      "Fold 2 Recall: 0.8998\n",
      "Fold 2 Precision: 0.8002\n",
      "Fold 2 F1-score: 0.8431\n",
      "Fold 2 Classification Report\n",
      ":              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.87       194\n",
      "           1       0.93      0.97      0.95        29\n",
      "           2       0.66      0.86      0.75     25518\n",
      "           3       0.62      0.82      0.71     69849\n",
      "           4       0.99      0.91      0.95    384410\n",
      "\n",
      "    accuracy                           0.89    480000\n",
      "   macro avg       0.80      0.90      0.84    480000\n",
      "weighted avg       0.92      0.89      0.90    480000\n",
      "\n",
      "Fold 2 Confusion Matrix:\n",
      "[[   183      0     11      0      0]\n",
      " [     0     28      1      0      0]\n",
      " [    28      0  22073   3127    290]\n",
      " [     8      0   8089  56956   4796]\n",
      " [     9      2   3451  31317 349631]]\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "stratified Fold 3-th XGBoost model training...\n",
      "Fold 3 Accuracy: 0.8915\n",
      "Fold 3 Recall: 0.9132\n",
      "Fold 3 Precision: 0.8059\n",
      "Fold 3 F1-score: 0.8518\n",
      "Fold 3 Classification Report\n",
      ":              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88       194\n",
      "           1       0.97      1.00      0.98        29\n",
      "           2       0.65      0.87      0.74     25518\n",
      "           3       0.62      0.82      0.70     69848\n",
      "           4       0.99      0.91      0.94    384411\n",
      "\n",
      "    accuracy                           0.89    480000\n",
      "   macro avg       0.81      0.91      0.85    480000\n",
      "weighted avg       0.91      0.89      0.90    480000\n",
      "\n",
      "Fold 3 Confusion Matrix:\n",
      "[[   189      0      5      0      0]\n",
      " [     0     29      0      0      0]\n",
      " [    33      1  22162   2975    347]\n",
      " [     5      0   8076  57026   4741]\n",
      " [     7      0   3838  32055 348511]]\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "stratified Fold 4-th XGBoost model training...\n",
      "Fold 4 Accuracy: 0.8865\n",
      "Fold 4 Recall: 0.8911\n",
      "Fold 4 Precision: 0.7926\n",
      "Fold 4 F1-score: 0.8333\n",
      "Fold 4 Classification Report\n",
      ":              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86       194\n",
      "           1       0.96      0.93      0.95        29\n",
      "           2       0.63      0.85      0.72     25518\n",
      "           3       0.61      0.81      0.69     69848\n",
      "           4       0.98      0.90      0.94    384411\n",
      "\n",
      "    accuracy                           0.89    480000\n",
      "   macro avg       0.79      0.89      0.83    480000\n",
      "weighted avg       0.91      0.89      0.89    480000\n",
      "\n",
      "Fold 4 Confusion Matrix:\n",
      "[[   187      0      7      0      0]\n",
      " [     0     27      2      0      0]\n",
      " [    40      1  21628   3411    438]\n",
      " [    11      0   8254  56587   4996]\n",
      " [     4      0   4261  33072 347074]]\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "stratified Fold 5-th XGBoost model training...\n",
      "Fold 5 Accuracy: 0.8786\n",
      "Fold 5 Recall: 0.8305\n",
      "Fold 5 Precision: 0.7660\n",
      "Fold 5 F1-score: 0.7884\n",
      "Fold 5 Classification Report\n",
      ":              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.88      0.78       195\n",
      "           1       1.00      0.83      0.91        29\n",
      "           2       0.54      0.79      0.64     25518\n",
      "           3       0.61      0.75      0.67     69848\n",
      "           4       0.98      0.91      0.94    384410\n",
      "\n",
      "    accuracy                           0.88    480000\n",
      "   macro avg       0.77      0.83      0.79    480000\n",
      "weighted avg       0.90      0.88      0.89    480000\n",
      "\n",
      "Fold 5 Confusion Matrix:\n",
      "[[   172      0     23      0      0]\n",
      " [     0     24      5      0      0]\n",
      " [    55      0  20109   4604    750]\n",
      " [    13      0  10699  52137   6999]\n",
      " [     6      0   6075  29065 349264]]\n",
      "----------------------------------------\n",
      "Stratified-K-Fold mean Accuracy: 0.8872\n",
      "Stratified-K-Fold mean Recall: 0.8844\n",
      "Stratified-K-Fold mean Precision: 0.7902\n",
      "Stratified-K-Fold mean F1-score: 0.8289\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "models = [] \n",
    "accuracy_scores = []\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "fi_scores = []\n",
    "classification_reports = []\n",
    "\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
    "    sample_weights_fold = sample_weights[train_idx]\n",
    "    print('-'*40)\n",
    "    print(f'stratified Fold {fold + 1}-th XGBoost model training...')\n",
    "    \n",
    "    # XGBoost\n",
    "    model = xgb.XGBClassifier(\n",
    "        tree_method='gpu_hist',  # GPU mode\n",
    "        gpu_id=0,\n",
    "        random_state=42,\n",
    "        sample_weight=sample_weights_fold,\n",
    "        use_label_encoder=False)\n",
    "    \n",
    "    # training and validation mornitoring\n",
    "\n",
    "    model.fit(X_train, y_train, sample_weight=sample_weights[train_idx])\n",
    "    models.append(model)\n",
    "    \n",
    "    y_val_pred = model.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    recall = recall_score(y_val, y_val_pred, average='macro')\n",
    "    precision = precision_score(y_val, y_val_pred, average='macro')\n",
    "    f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "    report = classification_report(y_val, y_val_pred)\n",
    "    conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Fold {fold + 1} Recall: {recall:.4f}\")\n",
    "    print(f\"Fold {fold + 1} Precision: {precision:.4f}\")\n",
    "    print(f\"Fold {fold + 1} F1-score: {f1:.4f}\")\n",
    "    print(f\"Fold {fold + 1} Classification Report\\n:{report}\")\n",
    "    print(f\"Fold {fold + 1} Confusion Matrix:\\n{conf_matrix}\")\n",
    "    print('-'*40)\n",
    "    \n",
    "    accuracy_scores.append(accuracy)\n",
    "    recall_scores.append(recall)\n",
    "    precision_scores.append(precision)\n",
    "    fi_scores.append(f1)\n",
    "    \n",
    "    \n",
    "print(f\"Stratified-K-Fold mean Accuracy: {np.mean(accuracy_scores):.4f}\")\n",
    "print(f\"Stratified-K-Fold mean Recall: {np.mean(recall_scores):.4f}\")\n",
    "print(f\"Stratified-K-Fold mean Precision: {np.mean(precision_scores):.4f}\")\n",
    "print(f\"Stratified-K-Fold mean F1-score: {np.mean(fi_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.drop(columns=['ID'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft Voting Inference Done.\n"
     ]
    }
   ],
   "source": [
    "n_classes = models[0].n_classes_ \n",
    "test_probabilities = np.zeros((len(X_test), n_classes)) # (600000, 5)\n",
    "\n",
    "for model in models:\n",
    "    test_probabilities += model.predict_proba(X_test) # (600000, 5)\n",
    "\n",
    "test_probabilities /= len(models)\n",
    "test_predictions = np.argmax(test_probabilities, axis=1)\n",
    "\n",
    "print('Soft Voting Inference Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_labels = le_target.inverse_transform(test_predictions)\n",
    "\n",
    "# row 단위 예측 결과를 test_data에 추가\n",
    "test_data = test_df.copy()  # 원본 유지\n",
    "test_data[\"pred_label\"] = y_test_pred_labels\n",
    "\n",
    "submission = test_data.groupby(\"ID\")[\"pred_label\"] \\\n",
    "    .agg(lambda x: x.value_counts().idxmax()) \\\n",
    "    .reset_index()\n",
    "\n",
    "submission.columns = [\"ID\", \"Segment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00000</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>TEST_99995</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>TEST_99996</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>TEST_99997</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>TEST_99998</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>TEST_99999</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID Segment\n",
       "0      TEST_00000       D\n",
       "1      TEST_00001       D\n",
       "2      TEST_00002       D\n",
       "3      TEST_00003       E\n",
       "4      TEST_00004       E\n",
       "...           ...     ...\n",
       "99995  TEST_99995       E\n",
       "99996  TEST_99996       E\n",
       "99997  TEST_99997       E\n",
       "99998  TEST_99998       C\n",
       "99999  TEST_99999       E\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./results/0327_xgboost_Stratified_5fold(class-weight).csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taehyeok",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
